{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9bb54771ab0e8de3f40d12e7f47d3c86fe58645b"
   },
   "source": [
    "# Shell APD Learning eXchange DnA Notebook\n",
    "\n",
    "## Predicting power usage in the eastern United States\n",
    "\n",
    "In this notebook, we will go through the cycle of a typical data science project, starting with data collection, cleaning, feature engineering and finally predictive modeling. We will also explore the three different categories of machine learning  problems, and how they work. By the end of this exercise notebook you should have a basic understanding of how data science works.\n",
    "\n",
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/next_steps.png?raw=true\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PJM Hourly Energy Consumption Data\n",
    "\n",
    "PJM is a regional transmission organization in the United States. It is part of the Eastern Interconnection grid operating an electric transmission system serving all or parts of Delaware, Illinois, Indiana, Kentucky, Maryland, Michigan, New Jersey, North Carolina, Ohio, Pennsylvania, Tennessee, Virginia, West Virginia, and the District of Columbia.\n",
    "\n",
    "We will be using hourly power consumption data from PJM's East grid. This data set ranges from 2002-2018. The data came from PJM's website and are given in megawatts (MW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION | CLASSIFICATION | CLUSTERING\n",
    "- | - | -\n",
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/LR.png?raw=true\" width=\"390\"> | <img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/CLASS1.png?raw=true\" width=\"390\"> | <img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/clustering.png?raw=true\" width=\"320\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import some python libraries and define functions we'll need <a class=\"anchor\" id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.dates as mdates\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "#     classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,7)) #\n",
    "    fig.patch.set_facecolor('white')\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    plt.figure(figsize=(10, 10)) \n",
    "    \n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "color_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "102c0bcb9cfc3be70922d8a308d4e29f02002c3e"
   },
   "source": [
    "# 2. Download the data to our notebook <a class=\"anchor\" id=\"data\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/robmoratore/ShellDnA/raw/master/data/PJM_Load.csv'\n",
    "df_full = pd.read_csv(url, sep = ',', date_parser=[\"date\"])\n",
    "df_full.index = pd.DatetimeIndex(df_full[\"date\"])\n",
    "df_full = df_full.drop(columns=['date'])\n",
    "pjme = df_full[['load', 'dayofyear']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the data <a class=\"anchor\" id=\"explore\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pjme.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot energy usage over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9ed25d7b8010577d04385c9c4077b6fffd7d409",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = pjme[\"load\"].plot(style='.', figsize=(15,5), color=color_pal[0], title='Energy consumption')\n",
    "_.set(xlabel=\"Time\", ylabel=\"Energy (MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c1c9cf0b6c70a8edd221810bb289b8837889288"
   },
   "source": [
    "# 4. Split the train and testing sets <a class=\"anchor\" id=\"traintest\"></a>\n",
    "\n",
    "We do that to ensure our model is able to generalize. That means, perform well on unseen data. If we train and test using the same data, the model will memorize that specific output and not learn it.\n",
    "\n",
    "We will use the data from 2015 on as our test set.\n",
    "\n",
    "![alt](https://github.com/robmoratore/ShellDnA/blob/master/data/images/train_test.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e5c8c6fd78d2ac35c628315a7f12ad19c84dddb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "split_date = '2015-01-01'\n",
    "pjme_train = pjme.loc[pjme.index <= split_date].copy()\n",
    "pjme_test = pjme.loc[pjme.index > split_date].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(pjme_test[\"load\"]) \\\n",
    "    .rename(columns={'load': 'TEST SET'}) \\\n",
    "    .join(pd.DataFrame(pjme_train[\"load\"]).rename(columns={'load': 'TRAINING SET'}), how='outer') \\\n",
    "    .plot(figsize=(15,5), title='Energy consumption', style='.')\n",
    "_ = ax.set(xlabel=\"Time\", ylabel=\"Energy (MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Regression - Can we predict energy use for a given hour? <a class=\"anchor\" id=\"model\"></a>\n",
    "\n",
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/bias.png?raw=true\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Start with a simple model - Linear Regression <a class=\"anchor\" id=\"linear\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(pjme_train[\"dayofyear\"].values.reshape(-1, 1), pjme_train[\"load\"].values.reshape(-1, 1))\n",
    "pjme_test['load_Prediction_lin'] = lin_reg.predict(pjme_test[\"dayofyear\"].values.reshape(-1, 1))\n",
    "_ = pjme_test[['load','load_Prediction_lin']].plot(figsize=(15, 5))\n",
    "_.set(xlabel=\"Time\", ylabel=\"Energy (MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how well our model performs\n",
    "Which error metrics would you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_true=pjme_test['load'], y_pred=pjme_test['load_Prediction_lin'])\n",
    "print (\"The Mean Squared Error (MSE) is \", round(mse, 2) , \"MW\\u00b2\")\n",
    "print (\"The Root Mean Squared Error (RMSE) is \", round(np.sqrt(mse), 2), \"MW\")\n",
    "print (\"The Mean Absolute Error (MAE) is \", round(mean_absolute_error(y_true=pjme_test['load'], y_pred=pjme_test['load_Prediction_lin']), 2), \"MW\")\n",
    "print (\"The Mean Absolute Percentage Error is \", round(mean_absolute_percentage_error(y_true=pjme_test['load'], y_pred=pjme_test['load_Prediction_lin']), 2), \"%\")\n",
    "print (\"The R\\u00b2 (coefficient of determination) regression score is \", round(r2_score(y_true=pjme_test['load'],y_pred=pjme_test['load_Prediction_lin']), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60ffc6c21d16280ee05faead916fd09c34fa490c"
   },
   "source": [
    "## 5.2 Get fancy with some Machine Learning - Gradient-boosted trees Model <a class=\"anchor\" id=\"xgbreg\"></a>\n",
    "\n",
    "This is one of the cleverest ways of combining multiple decision trees. Here, instead of having one single tree responsible for all the decisions, you use many trees on sequence. That means, the next tree does not try to predict the final result but the error of the previous tree. When you add all trees together, the results are generally very good\n",
    "\n",
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/xgb_reg.png?raw=true\" width=\"600\">\n",
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/xgb2.png?raw=true\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can you think of other ways of using multiple decision trees to make predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f608b0b457225f175c2eb1c4a74450747b095e93",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "include_variables = \"dayofyear\"\n",
    "reg = xgb.XGBRegressor(n_estimators=100)\n",
    "reg.fit(pjme_train[include_variables].values.reshape(-1, 1), pjme_train[\"load\"].values.reshape(-1, 1))\n",
    "pjme_test['load_Prediction_xgb'] = reg.predict(pjme_test[include_variables].values.reshape(-1, 1))\n",
    "_ = pjme_test[['load','load_Prediction_xgb']].plot(figsize=(15, 5))\n",
    "_.set(xlabel=\"Time\", ylabel=\"Energy (MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how well our model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_true=pjme_test['load'], y_pred=pjme_test['load_Prediction_xgb'])\n",
    "print (\"The Mean Squared Error (MSE) is \", round(mse, 2), \"MW\\u00b2\")\n",
    "print (\"The Root Mean Squared Error (RMSE) is \", round(np.sqrt(mse), 2), \"MW\")\n",
    "print (\"The Mean Absolute Error (MAE) is \", round(mean_absolute_error(y_true=pjme_test['load'], y_pred=pjme_test['load_Prediction_xgb']), 2), \"MW\")\n",
    "print (\"The Mean Absolute Percentage Error is \", round(mean_absolute_percentage_error(y_true=pjme_test['load'], y_pred=pjme_test['load_Prediction_xgb']), 2), \"%\")\n",
    "print (\"The R\\u00b2 (coefficient of determination) regression score is \", round(r2_score(y_true=pjme_test['load'],y_pred=pjme_test['load_Prediction_xgb']), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a40373b87cfcbbfac9be205b3dbacf56bb9bc3d0"
   },
   "source": [
    "# 6. Engineer New Features <a class=\"anchor\" id=\"featureengineer\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/pipeline.png?raw=true\" width=\"1200\">\n",
    "\n",
    "\n",
    "Here, we can create features to distinguish a seashell image from the Shell's logo. For example, we can have a feature \"red\" that represents the amount of red pixels present in the picture (in %, for example). That feature, will help the machine learning model to distinguish between the two images. Another example is the image's symmetry (yes/no).\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/shell.png?raw=true\" width=\"700\">\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "### Which features would you create to help predict load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pjme.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We created some features ahead of time for you "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_full.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = df_full.hist(bins=61, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Clean the dataset <a class=\"anchor\" id=\"cleaning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = df_full[\"temp\"].plot(style='k.', figsize=(15,5))\n",
    "_.set(xlabel=\"Time\", ylabel=\"Temperature (C)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_full = df_full[(df_full['temp']>=-25) & (df_full['temp']<=50)]\n",
    "_ = df_full[\"temp\"].plot(style='k.', figsize=(15,5))\n",
    "_.set(xlabel=\"Time\", ylabel=\"Temperature (C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(df_full.index)-df_full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_full = df_full.dropna()\n",
    "len(df_full.index)-df_full.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Retrain Gradient-boosted trees model with new features <a class=\"anchor\" id=\"modelnew\"></a>\n",
    "\n",
    "We can now retrain the Gradient-boosted trees model using the new features to see if performance improves.\n",
    "\n",
    "Here is a list of available features that can be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_full.drop(columns=['load']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select which features you would like to include in the model, and add them to the `include_variables` list bellow.\n",
    "Then check how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SELECT A COMBINATION OF FEATURES HERE\n",
    "include_variables = ['hour', 'dayofyear', 'quarter']\n",
    "#\n",
    "\n",
    "split_date = '2015-01-01'\n",
    "df_full_train = df_full.loc[df_full.index <= split_date].copy()\n",
    "df_full_test = df_full.loc[df_full.index > split_date].copy()\n",
    "\n",
    "df_full_test.index = pd.DatetimeIndex(df_full_test.index)\n",
    "df_full_train.index = pd.DatetimeIndex(df_full_train.index)\n",
    "\n",
    "reg = xgb.XGBRegressor(n_estimators=100)\n",
    "reg.fit(df_full_train[include_variables], df_full_train[\"load\"].values.reshape(-1, 1))\n",
    "df_full_test['load_Prediction_xgb'] = reg.predict(df_full_test[include_variables])\n",
    "_ = df_full_test[['load','load_Prediction_xgb']].plot(figsize=(15, 5))\n",
    "_.set(xlabel=\"Time\", ylabel=\"Energy (MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how well our model performs\n",
    "Which Feature gives you the lowest MAE and highest R$^{2}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_true=df_full_test['load'], y_pred=df_full_test['load_Prediction_xgb'])\n",
    "print (\"The Mean Squared Error (MSE) is \", round(mse, 2), \"MW\\u00b2\")\n",
    "print (\"The Root Mean Squared Error (RMSE) is \", round(np.sqrt(mse), 2), \"MW\")\n",
    "print (\"The Mean Absolute Error (MAE) is \", round(mean_absolute_error(y_true=df_full_test['load'], y_pred=df_full_test['load_Prediction_xgb']), 2), \"MW\")\n",
    "print (\"The Mean Absolute Percentage Error is \", round(mean_absolute_percentage_error(y_true=df_full_test['load'], y_pred=df_full_test['load_Prediction_xgb']), 2), \"%\")\n",
    "print (\"The R\\u00b2 (coefficient of determination) regression score is \", round(r2_score(y_true=df_full_test['load'],y_pred=df_full_test['load_Prediction_xgb']), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf8d62f71d3037055bb267d283d58e510b2f58ff"
   },
   "source": [
    "### Feature Importances\n",
    "Feature importance is a great way to get a general idea about which features the model is relying on most to make the prediction. This is a metric that simply sums up how many times each feature is split on.\n",
    "\n",
    "We can see that the day of year was most commonly used to split trees, while hour came in next. Quarter has low importance (never used in any splits even) due to the fact that it could be created by different dayofyear splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf9e389874f0463e33fc844a4821b27f32353e2c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plot_importance(reg, height=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f5225264a6ae80a24b4c2802eff73f576aa4867"
   },
   "source": [
    "## 8.1 Look at Worst and Best Predicted Days <a class=\"anchor\" id=\"bestworst\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb1fcc67506951b7a9708cce9463f899b98a7b37",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_full_test['error'] = df_full_test['load'] - df_full_test['load_Prediction_xgb']\n",
    "df_full_test['abs_error'] = df_full_test['error'].apply(np.abs)\n",
    "error_by_day = df_full_test.groupby(['year','month','dayofmonth']) \\\n",
    "    .mean()[['load','load_Prediction_xgb','error','abs_error']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6364555e8bed275076f6f6ee93c8537da3741aba",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_by_day.sort_values('abs_error', ascending=False).round(2).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(10)\n",
    "\n",
    "_ = df_full_test[['load','load_Prediction_xgb']][(df_full_test[['load','load_Prediction_xgb']].index>'2015-02-20') & (df_full_test[['load','load_Prediction_xgb']].index<'2015-02-21')].plot(ax=ax, style=['-','.'])\n",
    "plot = plt.suptitle('Worst Predicted Day')\n",
    "_.set(xlabel=\"Time\", ylabel=\"Energy (MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature in worst predicted day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full.index=='2015-02-20 00:00:00']['temp'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/cold.png?raw=true\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_by_day.sort_values('abs_error', ascending=True).round(2).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39eac1134b1278e7dd5f848ea03e7246d730b97f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(10)\n",
    "_ = df_full_test[['load','load_Prediction_xgb']][(df_full_test[['load','load_Prediction_xgb']].index>'2018-05-17') & (df_full_test[['load','load_Prediction_xgb']].index<'2018-05-18')].plot(ax=ax, style=['-','.'])\n",
    "plot = plt.suptitle('Best Predicted Day')\n",
    "_.set(xlabel=\"Time\", ylabel=\"Energy (MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. What are the next steps? <a class=\"anchor\" id=\"nextsteps\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/robmoratore/ShellDnA/blob/master/data/images/next_steps.png?raw=true\" width=\"1200\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
